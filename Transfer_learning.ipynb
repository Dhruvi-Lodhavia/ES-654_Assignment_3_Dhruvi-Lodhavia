{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfer_learning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNNbQfnS-Cyv"
      },
      "source": [
        "Upload dandelion vs Lily dataset from assignment folder and Unzip it "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyF6UqXoUiCa"
      },
      "source": [
        "!unzip 'dandelion_vs_lily.zip' -d 'dandelion_vs_lily'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjSvr7mEVDD1"
      },
      "source": [
        "Import necessary models and libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QT20jX2fbB4I"
      },
      "source": [
        "# vgg16 model used for transfer learning on the dogs and cats dataset\n",
        "import sys\n",
        "from matplotlib import pyplot\n",
        "from keras.utils import to_categorical\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlW1RWi8972r"
      },
      "source": [
        "training VGG1 without any image augmentation. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBkKZzOj6mes",
        "outputId": "aa5715a9-c2a7-4028-9e52-ce93b6d30016"
      },
      "source": [
        "from matplotlib import pyplot\n",
        "from matplotlib.image import imread\n",
        "\n",
        "def define_model():\n",
        "\t# load model\n",
        "\tmodel = VGG16(include_top=False, input_shape=(224, 224, 3))\n",
        "\t# mark loaded layers as not trainable\n",
        "\tfor layer in model.layers:\n",
        "\t\tlayer.trainable = False\n",
        "\t# add new classifier layers\n",
        "\tflat1 = Flatten()(model.layers[-1].output)\n",
        "\tclass1 = Dense(128, activation='relu', kernel_initializer='he_uniform')(flat1)\n",
        "\toutput = Dense(1, activation='sigmoid')(class1)\n",
        "\t# define new model\n",
        "\tmodel = Model(inputs=model.inputs, outputs=output)\n",
        "\t# compile model\n",
        "\topt = SGD(lr=0.001, momentum=0.9)\n",
        "\tmodel.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\treturn model\n",
        "\n",
        "def run_test_harness():\n",
        "\t# define model\n",
        "\tmodel = define_model()\n",
        "\t# create data generator\n",
        "\tdatagen = ImageDataGenerator()\n",
        "\t# specify imagenet mean values for centering\n",
        "\t# datagen.mean = [123.68, 116.779, 103.939]\n",
        "\t# prepare iterator\n",
        "\ttrain_it = datagen.flow_from_directory('/content/dandelion_vs_lily/dandelion_vs_lily/train',\n",
        "\t\tclass_mode='binary', batch_size=16, target_size=(224, 224))\n",
        "\ttest_it = datagen.flow_from_directory('/content/dandelion_vs_lily/dandelion_vs_lily/test',\n",
        "\t\tclass_mode='binary', batch_size=16, target_size=(224, 224))\n",
        "\t# fit model\n",
        "\thistory = model.fit(train_it, steps_per_epoch=len(train_it), epochs=4, verbose=1)\n",
        "\t# evaluate model\n",
        "\t_, acc = model.evaluate(test_it, steps=len(test_it), verbose=0)\n",
        "\tprint('> %.3f' % (acc * 100.0))\n",
        "\t# learning curves\n",
        "\tsummarize_diagnostics(history)\n",
        " \n",
        "def summarize_diagnostics(history):\n",
        "\t# plot loss\n",
        "\tpyplot.subplot(211)\n",
        "\tpyplot.title('Cross Entropy Loss')\n",
        "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
        "\t# pyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
        "\t# plot accuracy\n",
        "\tpyplot.subplot(212)\n",
        "\tpyplot.title('Classification Accuracy')\n",
        "\tpyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
        "\t# pyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
        "\t# save plot to file\n",
        "\tfilename = sys.argv[0].split('/')[-1]\n",
        "\tpyplot.savefig(filename + '_plot.png')\n",
        "\tpyplot.close()\n",
        " \n",
        "# entry point, run the test harness\n",
        "run_test_harness()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 60 images belonging to 2 classes.\n",
            "Found 20 images belonging to 2 classes.\n",
            "Epoch 1/4\n",
            "4/4 [==============================] - 28s 7s/step - loss: 6.7058 - accuracy: 0.6017\n",
            "Epoch 2/4\n",
            "4/4 [==============================] - 26s 7s/step - loss: 0.5664 - accuracy: 0.9633\n",
            "Epoch 3/4\n",
            "4/4 [==============================] - 26s 6s/step - loss: 1.7732e-20 - accuracy: 1.0000\n",
            "Epoch 4/4\n",
            "4/4 [==============================] - 26s 6s/step - loss: 1.0829e-31 - accuracy: 1.0000\n",
            "> 100.000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wtMt47Soq6Z",
        "outputId": "dd8051cb-f30e-44dd-9dba-bae2403c4a61"
      },
      "source": [
        "# vgg16 model used for transfer learning on the dogs and cats dataset\n",
        "import sys\n",
        "from matplotlib import pyplot\n",
        "from keras.utils import to_categorical\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        " \n",
        "# define cnn model\n",
        "def define_model():\n",
        "\t# load model\n",
        "\tmodel = VGG16(include_top=False, input_shape=(224, 224, 3))\n",
        "\t# mark loaded layers as not trainable\n",
        "\tfor layer in model.layers:\n",
        "\t\tlayer.trainable = False\n",
        "\t# add new classifier layers\n",
        "\tflat1 = Flatten()(model.layers[-1].output)\n",
        "\tclass1 = Dense(128, activation='relu', kernel_initializer='he_uniform')(flat1)\n",
        "\toutput = Dense(1, activation='sigmoid')(class1)\n",
        "\t# define new model\n",
        "\tmodel = Model(inputs=model.inputs, outputs=output)\n",
        "\t# compile model\n",
        "\topt = SGD(lr=0.001, momentum=0.9)\n",
        "\tmodel.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\treturn model\n",
        " \n",
        "# plot diagnostic learning curves\n",
        "def summarize_diagnostics(history):\n",
        "\t# plot loss\n",
        "\tpyplot.subplot(211)\n",
        "\tpyplot.title('Cross Entropy Loss')\n",
        "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
        "\t# pyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
        "\t# plot accuracy\n",
        "\tpyplot.subplot(212)\n",
        "\tpyplot.title('Classification Accuracy')\n",
        "\tpyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
        "\t# pyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
        "\t# save plot to file\n",
        "\tfilename = sys.argv[0].split('/')[-1]\n",
        "\tpyplot.savefig(filename + '_plot.png')\n",
        "\tpyplot.close()\n",
        " \n",
        "\n",
        "def run_test_harness1():\n",
        "  from matplotlib import pyplot\n",
        "  from matplotlib.image import imread\n",
        "\n",
        "\t# define model\n",
        "  model = define_model()\n",
        "\t# create data generator\n",
        "  datagen = ImageDataGenerator(\n",
        "        rotation_range=40,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest')\n",
        "\t# specify imagenet mean values for centering\n",
        "  datagen.mean = [123.68, 116.779, 103.939]\n",
        "\t# prepare iterator\n",
        "  train_it = datagen.flow_from_directory('/content/dandelion_vs_lily/dandelion_vs_lily/train',\n",
        "\t\tclass_mode='binary', batch_size=16, target_size=(224, 224))\n",
        "  test_it = datagen.flow_from_directory('/content/dandelion_vs_lily/dandelion_vs_lily/test',\n",
        "\t\tclass_mode='binary', batch_size=16, target_size=(224, 224))\n",
        "\t# fit model\n",
        "  history = model.fit_generator(train_it, steps_per_epoch=len(train_it), epochs=4, verbose=1)\n",
        "\t# evaluate model\n",
        "  _, acc = model.evaluate_generator(test_it, steps=len(test_it), verbose=0)\n",
        "  print('> %.3f' % (acc * 100.0))\n",
        "\t# learning curves\n",
        "  summarize_diagnostics(history)\n",
        " \n",
        "# entry point, run the test harness\n",
        "\n",
        "  \n",
        "  model.save('final_model_new.h5')\n",
        " \n",
        "# entry point, run the test harness\n",
        "run_test_harness1()\n",
        " \n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 60 images belonging to 2 classes.\n",
            "Found 20 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "4/4 [==============================] - 28s 7s/step - loss: 4.5996 - accuracy: 0.6976\n",
            "Epoch 2/4\n",
            "4/4 [==============================] - 27s 7s/step - loss: 0.0211 - accuracy: 0.9816\n",
            "Epoch 3/4\n",
            "4/4 [==============================] - 27s 7s/step - loss: 0.8408 - accuracy: 0.9454\n",
            "Epoch 4/4\n",
            "4/4 [==============================] - 27s 7s/step - loss: 9.1122e-08 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1877: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
            "  warnings.warn('`Model.evaluate_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "> 95.000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NomAXWfa9qax"
      },
      "source": [
        "Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjWX8zxH3_Ti",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3815e6e-e488-48fb-b156-04a96d7167a6"
      },
      "source": [
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.models import load_model\n",
        " \n",
        "# load and prepare the image\n",
        "def load_image(filename):\n",
        "\t# load the image\n",
        "\timg = load_img(filename, target_size=(224, 224))\n",
        "\t# convert to array\n",
        "\timg = img_to_array(img)\n",
        "\t# reshape into a single sample with 3 channels\n",
        "\timg = img.reshape(1, 224, 224, 3)\n",
        "\t# center pixel data\n",
        "\timg = img.astype('float32')\n",
        "\timg = img - [123.68, 116.779, 103.939]\n",
        "\treturn img\n",
        " \n",
        "# load an image and predict the class\n",
        "def run_example():\n",
        "\t# load the image\n",
        "\timg = load_image('/content/dandelion_vs_lily/dandelion_vs_lily/test/Dandelion/images (17).jfif.png')\n",
        "\tmodel = load_model('final_model_new.h5')\n",
        "\t# predict the class\n",
        "\tresult = model.predict(img)\n",
        "\tif(result>0.5):\n",
        "\t\tprint(\"Lily\")\n",
        "\telse:\n",
        "\t\tprint(\"Dandelion\")\n",
        "\t\n",
        " \n",
        "# entry point, run the example\n",
        "run_example()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dandelion\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}